import os
import h5py
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc
from model import GCN_CSS 

# ================= é…ç½®åŒºåŸŸ =================
HDF5_PATH = '/root/autodl-tmp/SS/GNN_CSS/GOLD_XYZ_OSC.0001_1024.hdf5'
MODEL_WEIGHTS_PATH = 'best_gcn_model.h5'

BATCH_SIZE = 128
NUM_NODES = 32
# ã€å…³é”®ä¿®æ”¹ã€‘è¿™é‡Œå¿…é¡»æ˜¯ 2
NUM_CLASSES = 2 
SIGMA = 1.0

# æ˜¾å­˜è®¾ç½®
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'
# ===========================================

def get_total_test_samples(hdf5_path, split_ratio=0.8):
    with h5py.File(hdf5_path, 'r') as f:
        total_len = f['X'].shape[0]
        start_idx = int(total_len * split_ratio)
        return total_len - start_idx, start_idx

def process_batch(X_raw, num_nodes=32, sigma=1.0):
    feature_dim = X_raw.shape[1] * X_raw.shape[2] // num_nodes
    X_reshaped = X_raw.reshape(-1, num_nodes, feature_dim)
    X_tensor = tf.convert_to_tensor(X_reshaped, dtype=tf.float32)

    diff = tf.expand_dims(X_tensor, 2) - tf.expand_dims(X_tensor, 1)
    dist_sq = tf.reduce_sum(tf.square(diff), axis=-1)
    A_batch = tf.exp(-dist_sq / (sigma ** 2))
    
    D = tf.reduce_sum(A_batch, axis=-1, keepdims=True)
    A_norm = A_batch / (D + 1e-6)
    
    return [X_tensor, A_norm]

def evaluate_entire_dataset(model, hdf5_path, start_idx, total_test_samples):
    print(f"ğŸš€ å¼€å§‹äºŒåˆ†ç±»å…¨é‡è¯„ä¼° (Spectrum Sensing)...")
    
    all_pred_probs = [] 
    all_true_classes = []
    all_snrs = []
    
    # æ—¢ç„¶æ˜¯äºŒåˆ†ç±»ï¼Œæˆ‘ä»¬åœ¨è¯„ä¼°æ—¶ä¹Ÿéœ€è¦æ¨¡æ‹Ÿå‡ºâ€œçº¯å™ªå£°â€æ•°æ®
    # å› ä¸º HDF5 åŸå§‹æ–‡ä»¶é‡Œåªæœ‰ä¿¡å·ã€‚
    # è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨ç®€å•çš„ç­–ç•¥ï¼šåªè¯„ä¼° HDF5 é‡Œçš„æ•°æ®ï¼Œè§†ä¸ºâ€œä¿¡å·(Class 1)â€
    # ä¸ºäº†ç”» ROCï¼Œæˆ‘ä»¬éœ€è¦è‡ªå·±åœ¨å†…å­˜é‡Œç”Ÿæˆå™ªå£°æ•°æ®(Class 0)
    
    num_batches = int(np.ceil(total_test_samples / BATCH_SIZE))
    
    with h5py.File(hdf5_path, 'r') as f:
        X_dataset = f['X']
        Z_dataset = f['Z']
        
        for i in range(num_batches):
            batch_start = start_idx + i * BATCH_SIZE
            batch_end = min(start_idx + (i + 1) * BATCH_SIZE, start_idx + total_test_samples)
            if batch_start >= batch_end: break
            
            # --- 1. è¯»å–çœŸå®ä¿¡å· (Class 1) ---
            X_signal = X_dataset[batch_start:batch_end]
            Z_signal = Z_dataset[batch_start:batch_end]
            current_batch_len = X_signal.shape[0]
            
            # --- 2. ç”Ÿæˆçº¯å™ªå£° (Class 0) ---
            # ä¸ºäº†ä¿æŒå¹³è¡¡ï¼Œç”ŸæˆåŒæ ·æ•°é‡çš„å™ªå£°
            X_noise = np.random.normal(0, 1.0, size=X_signal.shape).astype(np.float32)
            Z_noise = np.full((current_batch_len, 1), -100.0) # å™ªå£°SNRæ ‡è®°ä¸º -100
            
            # --- 3. åˆå¹¶ ---
            X_combined = np.concatenate([X_noise, X_signal], axis=0)
            # æ ‡ç­¾: 0=å™ªå£°, 1=ä¿¡å·
            Y_combined = np.concatenate([np.zeros(current_batch_len), np.ones(current_batch_len)])
            Z_combined = np.concatenate([Z_noise, Z_signal])
            
            # --- 4. é¢„æµ‹ ---
            inputs = process_batch(X_combined, NUM_NODES, SIGMA)
            preds = model.predict_on_batch(inputs) # (2*Batch, 2)
            
            # --- 5. å­˜å‚¨ ---
            all_pred_probs.append(preds)
            all_true_classes.append(Y_combined) # è¿™é‡Œå·²ç»æ˜¯ 0/1 æ•´æ•°äº†
            all_snrs.append(Z_combined)
            
            if i % 10 == 0:
                print(f"è¿›åº¦: {i}/{num_batches} batches processed...", end='\r')

    print("\nâœ… è¯„ä¼°å®Œæˆï¼Œæ­£åœ¨åˆå¹¶ç»“æœ...")
    y_probs = np.concatenate(all_pred_probs)
    y_true = np.concatenate(all_true_classes)
    snrs = np.concatenate(all_snrs)
    y_pred_class = np.argmax(y_probs, axis=1)
    
    return y_true, y_pred_class, y_probs, snrs

def plot_results(y_true, y_pred, y_probs, snrs):
    # --- 1. ROC Curve (äºŒåˆ†ç±»æ ¸å¿ƒ) ---
    plt.figure(figsize=(8, 8))
    
    # å–å‡ºå±äº Class 1 (ä¿¡å·) çš„æ¦‚ç‡
    y_score = y_probs[:, 1]
    
    fpr, tpr, _ = roc_curve(y_true, y_score)
    roc_auc = auc(fpr, tpr)
    
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Alarm Rate (P_fa)')
    plt.ylabel('Detection Probability (P_d)')
    plt.title('Spectrum Sensing ROC (Noise vs Signal)')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.savefig('roc_curve_binary.png')
    print("å·²ä¿å­˜: roc_curve_binary.png")
    
    # --- 2. Accuracy vs SNR (åªçœ‹ä¿¡å·éƒ¨åˆ†çš„æ£€æµ‹ç‡) ---
    # æˆ‘ä»¬åªå…³å¿ƒçœŸå®æ ‡ç­¾ä¸º 1 (ä¿¡å·) çš„æ ·æœ¬åœ¨ä¸åŒ SNR ä¸‹è¢«é¢„æµ‹å¯¹çš„æ¦‚ç‡ (Pd)
    snrs = snrs.flatten()
    # è¿‡æ»¤æ‰æˆ‘ä»¬æ‰‹åŠ¨ç”Ÿæˆçš„å™ªå£°(SNR=-100)
    signal_indices = np.where(snrs > -99)[0]
    
    if len(signal_indices) > 0:
        signal_snrs = snrs[signal_indices]
        signal_true = y_true[signal_indices]
        signal_pred = y_pred[signal_indices]
        
        unique_snrs = np.sort(np.unique(signal_snrs))
        pd_scores = []
        
        print("\n========== æ£€æµ‹æ¦‚ç‡ (Pd) vs SNR ==========")
        for snr in unique_snrs:
            idx = np.where(signal_snrs == snr)[0]
            if len(idx) == 0: continue
            # å¯¹äºä¿¡å·æ ·æœ¬ï¼Œå‡†ç¡®ç‡å°±æ˜¯æ£€æµ‹æ¦‚ç‡ (Pd)
            pd = accuracy_score(signal_true[idx], signal_pred[idx])
            pd_scores.append(pd)
            
        plt.figure(figsize=(10, 6))
        plt.plot(unique_snrs, pd_scores, 'r-o', linewidth=2, label='Detection Prob (Pd)')
        plt.title('Detection Probability vs SNR')
        plt.xlabel('SNR (dB)')
        plt.ylabel('Probability of Detection (Pd)')
        plt.grid(True)
        plt.savefig('pd_vs_snr.png')
        print("å·²ä¿å­˜: pd_vs_snr.png")

    # --- 3. Confusion Matrix ---
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Noise', 'Signal'], yticklabels=['Noise', 'Signal'])
    plt.title('Confusion Matrix (Binary)')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig('confusion_matrix_binary.png')
    print("å·²ä¿å­˜: confusion_matrix_binary.png")

if __name__ == "__main__":
    # 1. åŠ è½½æ¨¡å‹ (å¿…é¡»æ˜¯ 2 åˆ†ç±»æ¨¡å‹)
    print("æ­£åœ¨åŠ è½½äºŒåˆ†ç±»æ¨¡å‹...")
    model = GCN_CSS(num_classes=NUM_CLASSES, num_nodes=NUM_NODES)
    feat_dim = 1024 * 2 // NUM_NODES
    # è¿™é‡Œçš„ Build å½¢çŠ¶
    model.build([(None, NUM_NODES, feat_dim), (None, NUM_NODES, NUM_NODES)])
    
    try:
        model.load_weights(MODEL_WEIGHTS_PATH)
    except ValueError as e:
        print("\nâŒ é”™è¯¯: æƒé‡åŠ è½½å¤±è´¥ï¼")
        print("å¯èƒ½åŸå› : ä½ çš„ best_gcn_model.h5 æ˜¯æŒ‰ 24 ç±»è®­ç»ƒçš„ï¼Œä½†ç°åœ¨ä»£ç æ˜¯ 2 ç±»ã€‚")
        print("è§£å†³æ–¹æ³•: è¯·å…ˆè¿è¡Œ main.py é‡æ–°è®­ç»ƒäºŒåˆ†ç±»æ¨¡å‹ã€‚")
        exit()
    
    # 2. è·å–æµ‹è¯•é›†
    test_count, start_index = get_total_test_samples(HDF5_PATH)
    
    # 3. è¿è¡Œè¯„ä¼°
    # æ³¨æ„ï¼šæˆ‘ä»¬åœ¨ evaluate å‡½æ•°å†…éƒ¨ç”Ÿæˆäº†ä¸€åŠçš„å™ªå£°æ•°æ®ï¼Œæ‰€ä»¥å®é™…è¯„ä¼°æ ·æœ¬é‡ä¼šç¿»å€
    y_true, y_pred, y_probs, snrs = evaluate_entire_dataset(model, HDF5_PATH, start_index, test_count)
    
    # 4. ç»˜å›¾
    plot_results(y_true, y_pred, y_probs, snrs)