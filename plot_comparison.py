import os
import h5py
import numpy as np
import matplotlib.pyplot as plt
import argparse
import tensorflow as tf
from sklearn.svm import LinearSVC
from sklearn.cluster import MiniBatchKMeans
from sklearn.metrics import accuracy_score

# å¼•å…¥ä½ çš„æ¨¡å‹å®šä¹‰
from model import GCN_CSS, ANN_CSS, CNN_CSS

# ================= é…ç½®åŒºåŸŸ =================
# 1. ç²¾ç¡®åŒ¹é…æˆªå›¾ä¸­çš„ SNR èŒƒå›´
SNR_LIST = [-18, -16, -14, -12, -10, -8] 

# 2. é‡‡æ ·è®¾ç½®
SAMPLES_PER_SNR = 1000   # æ¯ä¸ªSNRç‚¹è¯„ä¼°çš„æ ·æœ¬æ•°
SKLEARN_TRAIN_SAMPLES = 20000  # è®­ç»ƒSVM/KMeansç”¨çš„æ ·æœ¬æ•°

# 3. é¢œè‰²æ–¹æ¡ˆ (åŒ¹é…æˆªå›¾)
COLORS = {
    'GCN-CSS': 'green',
    'CNN': 'blue',
    'ANN': 'cyan',
    'SVM': 'darkred',
    'KMeans': 'orange'
}
# ===========================================

def load_keras_model(model_class, weights_path, num_nodes, num_features):
    """å®ä¾‹åŒ– Keras æ¨¡å‹å¹¶åŠ è½½æƒé‡"""
    model = model_class(num_classes=2, num_nodes=num_nodes)
    try:
        # Buildæ¨¡å‹ä»¥åˆå§‹åŒ–æƒé‡å½¢çŠ¶
        model.build([(None, num_nodes, num_features), (None, num_nodes, num_nodes)])
        if os.path.exists(weights_path):
            model.load_weights(weights_path)
            print(f"âœ… [Keras] æˆåŠŸåŠ è½½: {weights_path}")
            return model
        else:
            print(f"âš ï¸ [Keras] ç¼ºå¤±æƒé‡: {weights_path} (å°†è·³è¿‡æ­¤æ¨¡å‹æˆ–è¾“å‡ºéšæœºç»“æœ)")
            return None
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å‡ºé”™ {weights_path}: {e}")
        return None

def train_sklearn_models(hdf5_path, num_nodes):
    """å¿«é€Ÿè®­ç»ƒ SVM å’Œ KMeans ç”¨äºå¯¹æ¯”"""
    print("\nâš™ï¸ æ­£åœ¨è®­ç»ƒåŸºå‡†æ¨¡å‹ (SVM & KMeans)...")
    
    with h5py.File(hdf5_path, 'r') as f:
        # è¯»å–ä¸€éƒ¨åˆ†æ•°æ®
        X = f['X'][:SKLEARN_TRAIN_SAMPLES]
        half = len(X) // 2
        
        # æ„é€ è®­ç»ƒé›†ï¼šä¸€åŠå™ªå£°ï¼Œä¸€åŠä¿¡å·
        X_signal = X[:half]
        batch_std = np.std(X_signal)
        X_noise = np.random.normal(0, batch_std, size=X_signal.shape)
        
        X_train = np.concatenate([X_noise, X_signal], axis=0)
        y_train = np.concatenate([np.zeros(half), np.ones(half)]) # 0:Noise, 1:Signal
        
        # Flatten (N, 32, Feat) -> (N, -1)
        X_train_flat = X_train.reshape(X_train.shape[0], -1)

    # SVM
    print("   -> Training SVM (LinearSVC)...")
    svm = LinearSVC(max_iter=1000, dual=False)
    svm.fit(X_train_flat, y_train)
    
    # KMeans
    print("   -> Training KMeans (Unsupervised)...")
    kmeans = MiniBatchKMeans(n_clusters=2, batch_size=256, n_init=3, random_state=42)
    kmeans.fit(X_train_flat)
    
    # è‡ªåŠ¨çº æ­£ KMeans çš„æ ‡ç­¾æ–¹å‘ (Cluster ID æ˜¯éšæœºçš„)
    sample_preds = kmeans.predict(X_train_flat[half:]) # é¢„æµ‹ä¿¡å·éƒ¨åˆ†
    # å¦‚æœå¤§éƒ¨åˆ†ä¿¡å·è¢«åˆ†æˆäº† 0ï¼Œè¯´æ˜ Cluster 0 æ˜¯ä¿¡å·ï¼Œéœ€è¦åè½¬
    invert_kmeans = np.mean(sample_preds) < 0.5 
    
    return svm, kmeans, invert_kmeans

def get_eval_data(f, snr, num_samples, num_nodes):
    """è·å–ç‰¹å®š SNR çš„æµ‹è¯•æ•°æ®"""
    all_snrs = f['Z'][:]
    indices = np.where(np.abs(all_snrs - snr) < 0.5)[0]
    
    if len(indices) == 0:
        return None, None, None
    
    selected = np.random.choice(indices, min(len(indices), num_samples), replace=False)
    X_signal = f['X'][selected]
    
    # ç”Ÿæˆå™ªå£°
    batch_std = np.std(X_signal)
    X_noise = np.random.normal(0, batch_std, size=X_signal.shape)
    
    # åˆå¹¶
    X_combined = np.concatenate([X_noise, X_signal], axis=0)
    Y_combined = np.concatenate([np.zeros(len(X_noise)), np.ones(len(X_signal))])
    
    # Keras è¾“å…¥æ ¼å¼
    feat_dim = X_combined.shape[1] * X_combined.shape[2] // num_nodes
    X_reshaped = X_combined.reshape(-1, num_nodes, feat_dim)
    X_tensor = tf.convert_to_tensor(X_reshaped, dtype=tf.float32)
    
    # åŠ¨æ€é‚»æ¥çŸ©é˜µè®¡ç®—
    diff = tf.expand_dims(X_tensor, 2) - tf.expand_dims(X_tensor, 1)
    dist_sq = tf.reduce_sum(tf.square(diff), axis=-1)
    A_val = tf.exp(-dist_sq) # sigma=1.0
    
    # Sklearn è¾“å…¥æ ¼å¼
    X_flat = X_combined.reshape(X_combined.shape[0], -1)
    
    return [X_tensor, A_val], X_flat, Y_combined

def plot_reproduction(results, snr_list):
    """ç»˜åˆ¶ä¸æˆªå›¾ä¸€è‡´çš„æŸ±çŠ¶å›¾"""
    print("\nğŸ¨ æ­£åœ¨ç»˜å›¾...")
    
    # ç¡®ä¿é¡ºåº: GCN, CNN, ANN, SVM, KMeans
    ordered_keys = ['GCN-CSS', 'CNN', 'ANN', 'SVM', 'KMeans']
    
    snrs = [str(s) for s in snr_list]
    x = np.arange(len(snrs))
    width = 0.15 # æŸ±å­å®½åº¦
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # ç»˜åˆ¶æ¯ä¸€ç»„æŸ±å­
    for i, model_name in enumerate(ordered_keys):
        if model_name not in results: continue
        
        scores = np.array(results[model_name]) * 100 # è½¬ä¸ºç™¾åˆ†æ¯”
        
        # è®¡ç®—åç§»é‡ï¼Œä½¿æŸ±å­å±…ä¸­
        offset = (i - len(ordered_keys)/2 + 0.5) * width
        
        ax.bar(x + offset, scores, width, 
               label=model_name, 
               color=COLORS.get(model_name, 'gray'),
               edgecolor='white', linewidth=0.5)

    # è®¾ç½®æ ·å¼
    ax.set_ylabel('Classification Accuracy (%)', fontsize=12)
    ax.set_xlabel('SNR (dB)', fontsize=12)
    ax.set_title('Classification Accuracy vs SNR', fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(snrs)
    
    # Yè½´èŒƒå›´ 0 - 100
    ax.set_ylim([0, 100])
    
    # å›¾ä¾‹
    ax.legend(loc='upper left', frameon=True)
    ax.grid(True, axis='y', linestyle='--', alpha=0.3)
    
    # ä¿å­˜
    save_path = 'reproduced_comparison.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å›¾ç‰‡å·²ä¿å­˜ä¸º: {save_path}")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--path', type=str, required=True, help='HDF5 dataset path')
    parser.add_argument('--nodes', type=int, default=32)
    args = parser.parse_args()
    
    # 1. å‡†å¤‡æ·±åº¦å­¦ä¹ æ¨¡å‹
    keras_configs = {
        'GCN-CSS': {'class': GCN_CSS, 'file': 'best_gcn_model.h5'},
        'CNN':     {'class': CNN_CSS, 'file': 'best_cnn_model.h5'},
        'ANN':     {'class': ANN_CSS, 'file': 'best_ann_model.h5'},
    }
    
    # è‡ªåŠ¨æ¨æ–­ç‰¹å¾ç»´åº¦
    with h5py.File(args.path, 'r') as f:
        sample_x = f['X'][0]
        num_feat = sample_x.shape[0] * sample_x.shape[1] // args.nodes
    
    loaded_models = {}
    for name, cfg in keras_configs.items():
        m = load_keras_model(cfg['class'], cfg['file'], args.nodes, num_feat)
        if m: loaded_models[name] = m

    # 2. è®­ç»ƒ Sklearn æ¨¡å‹
    svm, kmeans, km_invert = train_sklearn_models(args.path, args.nodes)
    
    # 3. æ”¶é›†ç»“æœ
    results = {k: [] for k in ['GCN-CSS', 'CNN', 'ANN', 'SVM', 'KMeans']}
    
    print("\nğŸ“Š å¼€å§‹è¯„ä¼°...")
    with h5py.File(args.path, 'r') as f:
        for snr in SNR_LIST:
            print(f" -> Testing SNR = {snr} dB", end='\r')
            
            k_in, sk_in, y_true = get_eval_data(f, snr, SAMPLES_PER_SNR, args.nodes)
            
            if k_in is None:
                for k in results: results[k].append(0.5) # é»˜è®¤çŒœæµ‹
                continue
                
            # è¯„ä¼° DL æ¨¡å‹
            for name, model in loaded_models.items():
                pred = np.argmax(model.predict(k_in, verbose=0), axis=1)
                results[name].append(accuracy_score(y_true, pred))
            
            # è¯„ä¼° SVM
            results['SVM'].append(accuracy_score(y_true, svm.predict(sk_in)))
            
            # è¯„ä¼° KMeans
            km_pred = kmeans.predict(sk_in)
            if km_invert: km_pred = 1 - km_pred
            results['KMeans'].append(accuracy_score(y_true, km_pred))
            
    # 4. ç»˜å›¾
    plot_reproduction(results, SNR_LIST)

if __name__ == "__main__":
    main()