import tensorflow as tf
import os
import multiprocessing

def train_model(model, train_ds, val_ds, epochs=10, lr=0.001, save_path='best_model.h5'):
    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)
    loss_fn = tf.keras.losses.CategoricalCrossentropy()
    
    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])
    
    checkpoint = tf.keras.callbacks.ModelCheckpoint(
        save_path, 
        monitor='val_accuracy', 
        save_best_only=True,
        save_weights_only=True,
        verbose=1
    )
    
    early_stop = tf.keras.callbacks.EarlyStopping(
        monitor='val_loss', 
        patience=10, 
        restore_best_weights=True
    )

    # è‡ªåŠ¨æ£€æµ‹ CPU æ ¸å¿ƒæ•°
    cpu_count = multiprocessing.cpu_count()
    # çº¿ç¨‹æ•°è®¾ç½®ï¼šé€šå¸¸è®¾ä¸º CPU æ ¸å¿ƒæ•°å³å¯
    workers = max(1, cpu_count)
    
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒ (Workers: {workers}, Mode: Multithreading)...")
    print(f"ğŸ’¾ æƒé‡ä¿å­˜è·¯å¾„: {save_path}")
    
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=epochs,
        callbacks=[checkpoint, early_stop],
        # ã€å…³é”®ä¿®å¤ã€‘
        # workers > 1: å¯ç”¨å¤šçº¿ç¨‹é¢„å–æ•°æ®ï¼Œè§£å†³ IO ç“¶é¢ˆ
        # use_multiprocessing=False: ç¦ç”¨å¤šè¿›ç¨‹ï¼Œé˜²æ­¢ CUDA å´©æºƒ
        workers=workers,
        use_multiprocessing=False, 
        max_queue_size=20
    )
    
    return history