import numpy as np
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from dataset import load_ideal_pu_signals, generate_h0_h1
from model import build_gcn_css
from dataloader import create_dataloader
from metrics import predict_by_snr, plot_pd_pf  # æ–°å¢å¯¼å…¥

# -------------------------- å¼ºåˆ¶CPUè®­ç»ƒ --------------------------
tf.config.set_visible_devices([], 'GPU')
tf.config.threading.set_intra_op_parallelism_threads(4)
tf.config.threading.set_inter_op_parallelism_threads(4)
tf.config.optimizer.set_jit(False)

# -------------------------- è®­ç»ƒ+æµ‹è¯•é€»è¾‘ --------------------------
def train_gcn_css(data_path: str, target_pf: float = 0.1):
    """
    è®­ç»ƒæ¨¡å‹ + æµ‹è¯•ã€Œå›ºå®šPfä¸‹ã€ä¸åŒSNRçš„Pd
    :param data_path: H5æ•°æ®æ–‡ä»¶è·¯å¾„
    :param target_pf: ç›®æ ‡å›ºå®šè™šè­¦æ¦‚ç‡ï¼ˆé»˜è®¤0.1ï¼‰
    """
    # 1. åŠ è½½PUä¿¡å·
    ideal_pu = load_ideal_pu_signals(
        data_path,
        min_snr=10,
        max_samples=500
    )
    
    # 2. ç”Ÿæˆè®­ç»ƒæ•°æ®
    (X_train, y_train), (X_val, y_val), (X_test, y_test) = generate_h0_h1(
        ideal_pu,
        total_samples=1000,
        target_snr_range=(-18, 10)
    )
    print(f"ğŸ“Š æ•°æ®åˆ’åˆ†ï¼šè®­ç»ƒé›†{len(X_train)} | éªŒè¯é›†{len(X_val)} | æµ‹è¯•é›†{len(X_test)}")

    # 3. åˆ›å»ºæ•°æ®åŠ è½½å™¨
    batch_size = 2
    train_loader = create_dataloader(X_train, y_train, batch_size=batch_size, shuffle=True)
    val_loader = create_dataloader(X_val, y_val, batch_size=batch_size, shuffle=False)
    test_loader = create_dataloader(X_test, y_test, batch_size=batch_size, shuffle=False)

    # 4. æ„å»º+è®­ç»ƒæ¨¡å‹
    model = build_gcn_css()
    model.summary()

    callbacks = [
        EarlyStopping(patience=2, restore_best_weights=True, monitor='val_loss'),
        ModelCheckpoint("best_gcn_css_cpu.h5", save_best_only=True, monitor='val_loss')
    ]

    print("ğŸš€ å¼€å§‹CPUè®­ç»ƒ...")
    history = model.fit(
        train_loader,
        validation_data=val_loader,
        epochs=5,
        callbacks=callbacks,
        verbose=1,
        use_multiprocessing=False,
        workers=1
    )

    # 5. åŸºç¡€æµ‹è¯•é›†è¯„ä¼°
    print("ğŸ“ˆ åŸºç¡€æµ‹è¯•é›†è¯„ä¼°...")
    test_loss, test_acc = model.evaluate(
        test_loader,
        verbose=1,
        use_multiprocessing=False,
        workers=1
    )
    print(f"âœ… åŸºç¡€æµ‹è¯•ç»“æœï¼šæŸå¤±={test_loss:.4f} | å‡†ç¡®ç‡={test_acc:.4f}")

    # 6. ä¸åŒSNRä¸‹çš„Pd/Pfæµ‹è¯•ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šä¼ å…¥target_pfï¼‰
    print(f"\n============= å¼€å§‹æµ‹è¯•ä¸åŒSNRä¸‹çš„Pd (å›ºå®šPf={target_pf:.2f}) =============")
    # å®šä¹‰è¦æµ‹è¯•çš„SNRåˆ—è¡¨ï¼ˆè¦†ç›–ä½/ä¸­/é«˜SNRï¼‰
    test_snr_list = [-18, -12, -6, 0, 6, 10]
    # è®¡ç®—ã€Œå›ºå®šPfä¸‹ã€çš„Pd
    snr_results = predict_by_snr(
        model=model,
        ideal_pu=ideal_pu,
        snr_list=test_snr_list,
        target_pf=target_pf,  # ä¼ å…¥å›ºå®šPfå€¼
        n_samples_per_snr=100  # æ¯ä¸ªSNRæµ‹è¯•100ä¸ªH0+100ä¸ªH1æ ·æœ¬
    )
    
    # 7. æ‰“å°æ±‡æ€»ç»“æœï¼ˆçªå‡ºå›ºå®šPfï¼‰
    print(f"\n============= å›ºå®šPf={target_pf:.2f} ä¸‹Pd/Pfæ±‡æ€»ç»“æœ =============")
    for snr in sorted(snr_results.keys()):
        pd, actual_pf = snr_results[snr]
        print(f"SNR={snr}dB: Pd={pd:.4f}, å®é™…Pf={actual_pf:.4f} (ç›®æ ‡Pf={target_pf:.2f})")
    
    # 8. ç»˜åˆ¶ã€Œå›ºå®šPfä¸‹ã€çš„Pd-SNRæ›²çº¿ï¼ˆä¼ å…¥target_pfï¼‰
    plot_pd_pf(
        snr_results,
        target_pf=target_pf,
        save_path=f"pd_pf_curve_fixed_pf_{target_pf:.2f}.png"  # æ–‡ä»¶åæ ‡æ³¨å›ºå®šPfå€¼
    )

    return model, snr_results

if __name__ == "__main__":
    DATA_PATH = "/root/autodl-tmp/SS/GOLD_XYZ_OSC.0001_1024.hdf5"
    # å¯è‡ªå®šä¹‰å›ºå®šPfå€¼ï¼ˆå¦‚0.05/0.1/0.2ï¼‰
    TARGET_PF = 0.1
    model, snr_results = train_gcn_css(DATA_PATH, target_pf=TARGET_PF)